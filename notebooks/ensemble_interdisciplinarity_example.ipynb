{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSTML Ensemble Interdisciplinarity Analysis Example\n",
    "\n",
    "This notebook demonstrates how to use the MSTML framework for ensemble interdisciplinarity analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Ensemble interdisciplinarity analysis measures how interdisciplinary author teams are by analyzing their topic distributions across a hierarchical topic model. The analysis includes:\n",
    "\n",
    "1. **Document Interdisciplinarity Scoring**: Measuring how diverse the topics are within author teams\n",
    "2. **Pairwise Topic Analysis**: Analyzing interdisciplinarity between specific topic pairs\n",
    "3. **Link Prediction**: Using hierarchical random graphs to predict collaboration likelihood\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "1. Run `python setup_mstml.py` to set up the environment\n",
    "2. Place your preprocessed data in `data/clean/` directory\n",
    "3. Ensure your data follows the standard MSTML DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the source directory to Python path\n",
    "sys.path.append('../source')\n",
    "\n",
    "# Import MSTML components\n",
    "from source import (\n",
    "    MstmlEnsembleInterdisciplinarity, \n",
    "    MstmlParams, \n",
    "    MstmlEmbedType,\n",
    "    GdltmParams\n",
    ")\n",
    "\n",
    "from source.mstml_library import (\n",
    "    score_interdisciplinarity,\n",
    "    compute_interdisciplinarity_score_fast,\n",
    "    compute_pairwise_interdisciplinarity,\n",
    "    calculate_major_n_topic_score,\n",
    "    get_nth_item_from_ordered_dict,\n",
    "    compute_link_likelihood_scores\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the analysis parameters and data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_NAME = \"your_dataset\"  # Change this to your dataset name\n",
    "DATA_PATH = f\"../data/clean/{DATASET_NAME}.pkl\"  # Path to your preprocessed data\n",
    "\n",
    "# Analysis parameters\n",
    "CUT_HEIGHT = 0.5  # Dendrogram cut height for topic clustering\n",
    "N_HOT = 1  # Number of \"hot\" topics per author\n",
    "MIN_HOT_THRESHOLD = 0.2  # Minimum threshold for hot topics\n",
    "N_TOPICS = 20  # Number of topics for LDA\n",
    "\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Cut height: {CUT_HEIGHT}\")\n",
    "print(f\"N-hot: {N_HOT}\")\n",
    "print(f\"Topics: {N_TOPICS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load and validate the preprocessed data. The data should be a pandas DataFrame with the following columns:\n",
    "- `title`: Document title\n",
    "- `abstract`: Document abstract/content  \n",
    "- `authors_parsed`: List of author names\n",
    "- `authorID`: List of author IDs\n",
    "- `date`: Publication date\n",
    "- `text_processed`: Preprocessed text for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"❌ Data file not found: {DATA_PATH}\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Run the preprocessing scripts to create clean data\")\n",
    "    print(\"2. Updated the DATASET_NAME variable above\")\n",
    "    print(\"3. Placed your data in the correct directory\")\n",
    "    raise FileNotFoundError(f\"Data file not found: {DATA_PATH}\")\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_pickle(DATA_PATH)\n",
    "\n",
    "print(f\"✓ Loaded dataset with {len(df)} documents\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Validate required columns\n",
    "required_columns = ['title', 'authors_parsed', 'authorID', 'text_processed']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"❌ Missing required columns: {missing_columns}\")\n",
    "    raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "print(\"✓ Data validation passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Explore the dataset to understand its structure and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total documents: {len(df)}\")\n",
    "print(f\"Unique authors: {len(set([author for authors in df['authorID'] for author in authors]))}\")\n",
    "print(f\"Average authors per document: {df['authorID'].apply(len).mean():.2f}\")\n",
    "print(f\"Max authors per document: {df['authorID'].apply(len).max()}\")\n",
    "\n",
    "# Author collaboration distribution\n",
    "author_counts = df['authorID'].apply(len)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "author_counts.hist(bins=20, alpha=0.7)\n",
    "plt.xlabel('Number of Authors per Document')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Authors per Document')\n",
    "\n",
    "# Publication timeline\n",
    "plt.subplot(1, 2, 2)\n",
    "df['date'].dt.year.value_counts().sort_index().plot(kind='line')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Publications')\n",
    "plt.title('Publications Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Setup\n",
    "\n",
    "Set up the topic modeling pipeline using GDLTM (Geometry-Driven Longitudinal Topic Model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GDLTM parameters\n",
    "gdltm_params = GdltmParams(\n",
    "    dset=DATASET_NAME,\n",
    "    dsub=\"ensemble_analysis\",\n",
    "    ntopics=N_TOPICS,\n",
    "    nchunks=1,  # Single time chunk for ensemble analysis\n",
    "    chunk_len=len(df),\n",
    "    passes=10,\n",
    "    iterations=50,\n",
    "    eval_every=10\n",
    ")\n",
    "\n",
    "# Create MSTML parameters\n",
    "mstml_params = MstmlParams(\n",
    "    gdltm_params=gdltm_params,\n",
    "    fwd_window=3,\n",
    "    embed_type=MstmlEmbedType.SLC_TPC_HELLINGER_SIM_DISTN,\n",
    "    alpha=0.5,\n",
    "    beta=1.0\n",
    ")\n",
    "\n",
    "print(\"✓ Parameters configured\")\n",
    "mstml_params.print_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Ensemble Interdisciplinarity Analysis\n",
    "\n",
    "Create the ensemble interdisciplinarity analysis object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ensemble interdisciplinarity analysis\n",
    "ensemble_analysis = MstmlEnsembleInterdisciplinarity(\n",
    "    params=mstml_params,\n",
    "    cut_height=CUT_HEIGHT,\n",
    "    n_hot=N_HOT,\n",
    "    min_hot_threshold=MIN_HOT_THRESHOLD\n",
    ")\n",
    "\n",
    "print(f\"✓ Ensemble analysis initialized\")\n",
    "print(f\"Experiment directory: {ensemble_analysis.exp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Training\n",
    "\n",
    "Train the topic model on the document corpus.\n",
    "\n",
    "**Note**: This is a simplified example. In practice, you would use the full GDLTM pipeline with proper preprocessing, chunking, and hierarchical topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a placeholder for the actual topic modeling pipeline\n",
    "# In practice, you would:\n",
    "# 1. Use GDLTM to train topic models on time chunks\n",
    "# 2. Build hierarchical topic dendrograms\n",
    "# 3. Create author-topic distributions\n",
    "# 4. Build co-authorship networks\n",
    "\n",
    "print(\"⚠️  Topic modeling pipeline placeholder\")\n",
    "print(\"In a complete implementation, this would include:\")\n",
    "print(\"1. Document preprocessing and chunking\")\n",
    "print(\"2. LDA topic model training\")\n",
    "print(\"3. Hierarchical topic clustering\")\n",
    "print(\"4. Author-topic distribution computation\")\n",
    "print(\"5. Co-authorship network construction\")\n",
    "\n",
    "# For demonstration, create mock data structures\n",
    "# Replace this with actual topic modeling results\n",
    "\n",
    "# Mock author-topic distributions (replace with real data)\n",
    "unique_authors = list(set([author for authors in df['authorID'] for author in authors]))\n",
    "n_authors = len(unique_authors)\n",
    "\n",
    "# Create random author-topic distributions for demonstration\n",
    "np.random.seed(42)\n",
    "author_topic_distributions = {}\n",
    "for author in unique_authors:\n",
    "    # Random topic distribution that sums to 1\n",
    "    dist = np.random.dirichlet(np.ones(N_TOPICS))\n",
    "    author_topic_distributions[author] = dist\n",
    "\n",
    "print(f\"✓ Created mock author-topic distributions for {n_authors} authors\")\n",
    "print(\"⚠️  Replace this with actual topic modeling results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Interdisciplinarity Analysis\n",
    "\n",
    "Compute interdisciplinarity scores for documents based on their author teams' topic diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document-authors mapping\n",
    "doc_authors = {}\n",
    "for idx, row in df.iterrows():\n",
    "    doc_authors[idx] = row['authorID']\n",
    "\n",
    "# Create author-to-documents mapping\n",
    "author_to_docs = {}\n",
    "for doc_id, authors in doc_authors.items():\n",
    "    for author in authors:\n",
    "        if author not in author_to_docs:\n",
    "            author_to_docs[author] = []\n",
    "        author_to_docs[author].append(doc_id)\n",
    "\n",
    "print(f\"✓ Created mappings for {len(doc_authors)} documents and {len(author_to_docs)} authors\")\n",
    "\n",
    "# Compute interdisciplinarity scores\n",
    "interdisciplinarity_scores = compute_interdisciplinarity_score_fast(\n",
    "    doc_authors=doc_authors,\n",
    "    author_distributions=author_topic_distributions,\n",
    "    author_to_docs=author_to_docs,\n",
    "    n_hot=N_HOT,\n",
    "    min_hot_threshold=MIN_HOT_THRESHOLD\n",
    ")\n",
    "\n",
    "print(f\"✓ Computed interdisciplinarity scores for {len(interdisciplinarity_scores)} documents\")\n",
    "\n",
    "# Display top interdisciplinary documents\n",
    "print(\"\\nTop 10 Most Interdisciplinary Documents:\")\n",
    "for i in range(min(10, len(interdisciplinarity_scores))):\n",
    "    doc_id, score = get_nth_item_from_ordered_dict(interdisciplinarity_scores, i)\n",
    "    title = df.loc[doc_id, 'title'][:80] + \"...\" if len(df.loc[doc_id, 'title']) > 80 else df.loc[doc_id, 'title']\n",
    "    n_authors = len(df.loc[doc_id, 'authorID'])\n",
    "    print(f\"{i+1:2d}. Score: {score:.3f} | Authors: {n_authors} | {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interdisciplinarity Score Analysis\n",
    "\n",
    "Analyze the distribution of interdisciplinarity scores and their relationship with document characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scores to DataFrame for analysis\n",
    "scores_df = pd.DataFrame([\n",
    "    {'doc_id': doc_id, 'interdisciplinarity_score': score}\n",
    "    for doc_id, score in interdisciplinarity_scores.items()\n",
    "])\n",
    "\n",
    "# Merge with document metadata\n",
    "analysis_df = scores_df.merge(\n",
    "    df[['title', 'authorID', 'date']].reset_index().rename(columns={'index': 'doc_id'}),\n",
    "    on='doc_id'\n",
    ")\n",
    "analysis_df['n_authors'] = analysis_df['authorID'].apply(len)\n",
    "analysis_df['year'] = analysis_df['date'].dt.year\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Score distribution\n",
    "axes[0, 0].hist(analysis_df['interdisciplinarity_score'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Interdisciplinarity Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Interdisciplinarity Scores')\n",
    "\n",
    "# Score vs number of authors\n",
    "axes[0, 1].scatter(analysis_df['n_authors'], analysis_df['interdisciplinarity_score'], alpha=0.6)\n",
    "axes[0, 1].set_xlabel('Number of Authors')\n",
    "axes[0, 1].set_ylabel('Interdisciplinarity Score')\n",
    "axes[0, 1].set_title('Interdisciplinarity vs Team Size')\n",
    "\n",
    "# Score over time\n",
    "yearly_scores = analysis_df.groupby('year')['interdisciplinarity_score'].mean()\n",
    "axes[1, 0].plot(yearly_scores.index, yearly_scores.values, marker='o')\n",
    "axes[1, 0].set_xlabel('Year')\n",
    "axes[1, 0].set_ylabel('Average Interdisciplinarity Score')\n",
    "axes[1, 0].set_title('Interdisciplinarity Trends Over Time')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Box plot by team size categories\n",
    "analysis_df['team_size_category'] = pd.cut(\n",
    "    analysis_df['n_authors'], \n",
    "    bins=[0, 1, 2, 3, 5, float('inf')], \n",
    "    labels=['Solo', '2 authors', '3 authors', '4-5 authors', '6+ authors']\n",
    ")\n",
    "sns.boxplot(data=analysis_df, x='team_size_category', y='interdisciplinarity_score', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Team Size Category')\n",
    "axes[1, 1].set_ylabel('Interdisciplinarity Score')\n",
    "axes[1, 1].set_title('Interdisciplinarity by Team Size')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nInterdisciplinarity Score Statistics:\")\n",
    "print(analysis_df['interdisciplinarity_score'].describe())\n",
    "\n",
    "print(\"\\nCorrelation with team size:\")\n",
    "correlation = analysis_df['n_authors'].corr(analysis_df['interdisciplinarity_score'])\n",
    "print(f\"Pearson correlation: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Topic Interdisciplinarity\n",
    "\n",
    "Analyze interdisciplinarity between specific pairs of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise interdisciplinarity for a subset of topics\n",
    "# (Computing all pairs can be computationally expensive)\n",
    "selected_topics = list(range(min(5, N_TOPICS)))  # Analyze first 5 topics\n",
    "\n",
    "print(f\"Computing pairwise interdisciplinarity for topics: {selected_topics}\")\n",
    "\n",
    "pairwise_scores = compute_pairwise_interdisciplinarity(\n",
    "    doc_authors=doc_authors,\n",
    "    author_distributions=author_topic_distributions,\n",
    "    author_to_docs=author_to_docs,\n",
    "    topics=selected_topics,\n",
    "    n_hot=N_HOT,\n",
    "    min_hot_threshold=MIN_HOT_THRESHOLD\n",
    ")\n",
    "\n",
    "print(f\"✓ Computed pairwise scores for {len(pairwise_scores)} topic pairs\")\n",
    "\n",
    "# Create heatmap of maximum interdisciplinarity scores between topic pairs\n",
    "n_topics = len(selected_topics)\n",
    "heatmap_matrix = np.zeros((n_topics, n_topics))\n",
    "\n",
    "for i in range(n_topics):\n",
    "    for j in range(i + 1, n_topics):\n",
    "        topic_pair = (selected_topics[i], selected_topics[j])\n",
    "        if topic_pair in pairwise_scores:\n",
    "            scores = pairwise_scores[topic_pair]\n",
    "            max_score = max(scores.values()) if scores else 0\n",
    "            heatmap_matrix[i, j] = max_score\n",
    "            heatmap_matrix[j, i] = max_score\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    heatmap_matrix, \n",
    "    annot=True, \n",
    "    fmt='.3f', \n",
    "    xticklabels=[f'Topic {i}' for i in selected_topics],\n",
    "    yticklabels=[f'Topic {i}' for i in selected_topics],\n",
    "    cmap='viridis'\n",
    ")\n",
    "plt.title('Maximum Interdisciplinarity Scores Between Topic Pairs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show top interdisciplinary documents for a specific topic pair\n",
    "example_pair = (selected_topics[0], selected_topics[1])\n",
    "if example_pair in pairwise_scores:\n",
    "    pair_scores = pairwise_scores[example_pair]\n",
    "    print(f\"\\nTop 5 documents for topic pair {example_pair}:\")\n",
    "    for i in range(min(5, len(pair_scores))):\n",
    "        doc_id, score = get_nth_item_from_ordered_dict(pair_scores, i)\n",
    "        title = df.loc[doc_id, 'title'][:60] + \"...\" if len(df.loc[doc_id, 'title']) > 60 else df.loc[doc_id, 'title']\n",
    "        print(f\"{i+1}. Score: {score:.3f} | {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary and Export\n",
    "\n",
    "Summarize the analysis results and export them for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_summary = {\n",
    "    'dataset': DATASET_NAME,\n",
    "    'n_documents': len(df),\n",
    "    'n_authors': len(unique_authors),\n",
    "    'n_topics': N_TOPICS,\n",
    "    'cut_height': CUT_HEIGHT,\n",
    "    'n_hot': N_HOT,\n",
    "    'min_hot_threshold': MIN_HOT_THRESHOLD,\n",
    "    'mean_interdisciplinarity': analysis_df['interdisciplinarity_score'].mean(),\n",
    "    'std_interdisciplinarity': analysis_df['interdisciplinarity_score'].std(),\n",
    "    'max_interdisciplinarity': analysis_df['interdisciplinarity_score'].max(),\n",
    "    'correlation_team_size': correlation\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENSEMBLE INTERDISCIPLINARITY ANALYSIS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for key, value in results_summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Export results\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export interdisciplinarity scores\n",
    "analysis_df.to_csv(results_dir / f\"{DATASET_NAME}_interdisciplinarity_scores.csv\", index=False)\n",
    "\n",
    "# Export summary\n",
    "import json\n",
    "with open(results_dir / f\"{DATASET_NAME}_ensemble_summary.json\", 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results exported to {results_dir}\")\n",
    "print(\"Files created:\")\n",
    "print(f\"  - {DATASET_NAME}_interdisciplinarity_scores.csv\")\n",
    "print(f\"  - {DATASET_NAME}_ensemble_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook provides a foundation for ensemble interdisciplinarity analysis. To extend the analysis:\n",
    "\n",
    "1. **Implement Full Topic Modeling Pipeline**: Replace the mock data with actual GDLTM topic modeling results\n",
    "2. **Hierarchical Topic Analysis**: Use the hierarchical random graph functionality for link prediction\n",
    "3. **Network Analysis**: Analyze co-authorship networks and their relationship to interdisciplinarity\n",
    "4. **Temporal Analysis**: Extend to longitudinal analysis to see how interdisciplinarity changes over time\n",
    "5. **Domain-Specific Analysis**: Customize the analysis for your specific research domain\n",
    "\n",
    "## References\n",
    "\n",
    "- Original AToMS research and methodology\n",
    "- GDLTM: Geometry-Driven Longitudinal Topic Model\n",
    "- Hierarchical Random Graphs for collaboration prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}